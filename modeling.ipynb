{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.types import *\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from src.util import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import pyspark.sql.functions as F\n",
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from pyspark.ml.feature import CountVectorizer, IDF\n",
    "# from pyspark.sql.functions import udf\n",
    "# from pyspark.sql import Row\n",
    "# PUNCTUATION = set(string.punctuation)\n",
    "# STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "# from sklearn import preprocessing\n",
    "# import codecs\n",
    "# import string\n",
    "# import re\n",
    "# from pyspark.sql.functions import isnan, when, count, col\n",
    "# import spacy\n",
    "# from spacy.lang.en import English\n",
    "# from spacy import displacy\n",
    "# nlp = spacy.load('en_core_web_md')\n",
    "# import logging\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\n",
    " 's3://aws-logs-816063959671-us-east-1/data/tldr-training-data.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308706"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df.sample(withReplacement=False, fraction=0.1)\n",
    "subset.cache()\n",
    "subset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- content_len: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- normalizedBody: string (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- summary_len: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# util.word_length('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as F\n",
    "import pickle\n",
    "PUNCTUATION = set(string.punctuation)\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "addl_punctuation = set(['...', '`', '¿','⸮', '``', \"''\"])\n",
    "PUNCTUATION = PUNCTUATION.union(addl_punctuation)\n",
    "\n",
    "CONTRACTIONS = {\n",
    "\"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\"he's\": \"he is\",\"how'd\": \"how did\",\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\"i'd\": \"i would\",\"i'll\": \"i will\",\"i'm\": \"i am\",\"i've\": \"i have\",\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\"it'll\": \"it will\",\"it's\": \"it is\",\"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\"mightn't\": \"might not\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\"oughtn't\": \"ought not\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\"she's\": \"she is\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\"there'd\": \"there had\",\"there's\": \"there is\",\"they'd\": \"they would\",\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\"they've\": \"they have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\"what'll\": \"what will\",\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\"what've\": \"what have\",\"where'd\": \"where did\",\"where's\": \"where is\",\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\"won't\": \"will not\",\"wouldn't\": \"would not\",\"you'd\": \"you would\",\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}\n",
    "\n",
    "def clean_text(text, remove_stopwords=True):\n",
    "    text = text.lower()\n",
    "\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = [CONTRACTIONS[w] if w in CONTRACTIONS else w for w in text]\n",
    "\n",
    "        text = \" \".join(new_text)\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in PUNCTUATION]\n",
    "    if remove_stopwords==True:\n",
    "        tokens = [w for w in tokens if w not in STOPWORDS]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def word_length(string):\n",
    "    tokens = word_tokenize(string)\n",
    "    tokens = [w for w in tokens if w not in PUNCTUATION]\n",
    "    return len(tokens)\n",
    "\n",
    "def clean_data(df, n_words_summary=50, remove_stopwords=True):\n",
    "    # Get rid of all rows where subreddit is null (these are spam)\n",
    "    df = df.filter(df.subreddit.isNotNull())\n",
    "    # Lowercase columns:\n",
    "    for col in ['body','content','normalizedBody','subreddit','summary','title']:\n",
    "        df = df.withColumn(col, F.lower(F.col(col)))\n",
    "    # Converts 'null' strings in the title column back to null values\n",
    "    df = df.withColumn('title', when(df.title == 'null', F.lit(None)).otherwise(df.title))\n",
    "    \n",
    "\n",
    "    # Creat edit(bool) and edit_len columns, while removing 'edit:%' from summary column\n",
    "    split_col = F.split(df['summary'], '(edit:|[^a-z]edit)')\n",
    "    df = df.withColumn('edit', split_col.getItem(1))\n",
    "    df = df.withColumn('summary', split_col.getItem(0))\n",
    "    function = udf(word_length, LongType())\n",
    "    df = df.withColumn('summary_len', function(df.summary))\n",
    "        # Creates edit_len column, number of words from 'edit'\n",
    "    df = df.withColumn('edit', df.edit).na.fill('')\n",
    "    df = df.withColumn('edit_len', function(df.edit))\n",
    "        # Converts -1 in edit_len column to null\n",
    "    df = df.withColumn('edit_len',\n",
    "        when(df.edit_len == -1, F.lit(0)).otherwise(df.edit_len))\n",
    "    df = df.withColumn('edit', when(df.edit.isNull(), F.lit(0)).otherwise(1))\n",
    "    # Remove all rows where summary contains less than 5 words\n",
    "    df = df.filter(df.summary_len >= 5)\n",
    "    # Remove all rows where summary contains greater than n_words_summary words\n",
    "    df = df.filter((df.summary_len <= n_words_summary))\n",
    "    # Remove all rows where the summary length is not less than 50% of the content length\n",
    "    df = df.filter(df.summary_len <= df.content_len*0.5)\n",
    "    # Clean Content column\n",
    "    cleantext_udf = udf(clean_text, StringType())\n",
    "    df = df.withColumn('content', cleantext_udf(df.content, F.lit(remove_stopwords)))\n",
    "    df = df.withColumn('summary', cleantext_udf(df.summary, F.lit(False)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = clean_data(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267253"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = newdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.drop(['body', 'normalizedBody', 'author', 'id', 'subreddit', 'subreddit_id',\n",
    "         'title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>content_len</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_len</th>\n",
       "      <th>edit</th>\n",
       "      <th>edit_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 month old son mcdonalds playplace little go...</td>\n",
       "      <td>142</td>\n",
       "      <td>my 10 month old molests a 5 year old</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great image 100 certain agree easy say `` rebe...</td>\n",
       "      <td>184</td>\n",
       "      <td>do not blame miserable parents for not realizi...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meant files mostly word really well actually g...</td>\n",
       "      <td>181</td>\n",
       "      <td>i act/post like i am high or something late at...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit defensive timings know defensive timings w...</td>\n",
       "      <td>121</td>\n",
       "      <td>either you invest in queens for aa and oversee...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kinda issue putting blame one party yes agree ...</td>\n",
       "      <td>231</td>\n",
       "      <td>riot should have had booths but at the same ti...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  content_len  \\\n",
       "0  10 month old son mcdonalds playplace little go...          142   \n",
       "1  great image 100 certain agree easy say `` rebe...          184   \n",
       "2  meant files mostly word really well actually g...          181   \n",
       "3  hit defensive timings know defensive timings w...          121   \n",
       "4  kinda issue putting blame one party yes agree ...          231   \n",
       "\n",
       "                                             summary  summary_len  edit  \\\n",
       "0               my 10 month old molests a 5 year old            9     1   \n",
       "1  do not blame miserable parents for not realizi...           22     1   \n",
       "2  i act/post like i am high or something late at...           11     1   \n",
       "3  either you invest in queens for aa and oversee...           27     1   \n",
       "4  riot should have had booths but at the same ti...           15     1   \n",
       "\n",
       "   edit_len  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdf.replace('', np.NaN)\n",
    "pdf = pdf.replace(float('nan'), np.NaN)\n",
    "pdf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review # 1\n",
      "my 10 month old molests a 5 year old\n",
      "10 month old son mcdonalds playplace little goofball adorable little girl climbs well cutest little thing ever 5. walks fiancee asks `` play '' points son said sure climbs starts playing well twenty minutes giggling laughing suddenly screams bloody murder turn around started laughing turns 10 month old son big 5 year old pinned pulling dress trying bite cheek adorably creepy climb pull easier said done ran promptly left mom\n",
      "\n",
      "Review # 2\n",
      "do not blame miserable parents for not realizing they would be miserable blame the culture that told them they would not be\n",
      "great image 100 certain agree easy say `` rebelled '' often facts matter grow environment full certain messages likely end believing true go college want life kids get 9-5 job responsible etc fair blame people listening things told entire lives insight realize bullshit escape rather need start challenging messages get anything smug sense superiority blaming people saying `` oh miserable kids well get buying kids happy crap '' instead need encourage people think decisions like presumably done come conclusions best rather society says best\n",
      "\n",
      "Review # 3\n",
      "i act/post like i am high or something late at night\n",
      "meant files mostly word really well actually guess meant change folders file 's permissions people could work would blind cause trouble mayhem see many people still try work blind many delete everything another fun thing would randomly give random pepple admin status/permission/access random stuff eg servers drives want watch world burn nice moral ethical mix two alot wth¿⸮ fone kerekted lot lot¡i nevermind crap default keyboard `` alot '' dictionary fuck-all unintuitive autocorrect `` stuf '' gets changed shit quotation marks always turned commas et cetera brother turned swype thought slow going turn ignacio wtf typed `` back '' without space shit ignacio would like non-genius version jigsaw kinda crappy edit\n",
      "\n",
      "Review # 4\n",
      "either you invest in queens for aa and overseer 's for detection or you make 3+ spores to cover all of your tech buildings bases and drones\n",
      "hit defensive timings know defensive timings watch pro games see terran put turrets certain point zerg lay spore crawlers advance common protoss timing cannon observer prevent burrowed warfare banshee harassment made 6 queens standard players strongly suggest getting upwards 4-6 queens terran specifically dealing early banshees hellions terms detection cloak banshees reason early lairs generally go lair tech +1 armor ranged done otherwise feel going far early\n",
      "\n",
      "Review # 5\n",
      "riot should have had booths but at the same time frost did break the rules\n",
      "kinda issue putting blame one party yes agree 154.37 repeating course riot booths least sort method blocking minimap offer many positive benefits almost necessity hell given chance would argue carmac idea booths look iem looking behind rules riot set place tournament began rules rules see guys running court basketball dribbling ball easier faster way see american footballers making horse-collar tackles good place get grip get penalized saying riot using frost fall guy redbeard posted might skipped rulings post `` hindsight potential visibility minimap screens players mistake despite on-site referees close monitoring player cams backstage stage design ensured players would turn 90 degrees able catch glimpse minimaps even possibility unfair play simply unacceptable ’ taking steps ensure minimap screens visible players ''\n",
      "\n",
      "Review # 6\n",
      "australia does a good job permanently resettling 80,000 refugees a year mostly from refugee camps boat people are the worst choice because of the risk they die in a boat accident other countries should step up their game\n",
      "particularly humane boat people made choice go refugee camp crappy choice stay home risk getting shot crappy dangerous choice go boat australia less crappy dangerous expensive choice unless australia logical destination indonesian ethnic minorities encouraged take dangerous voyage australia go refugee camp good chance end country treats refugees like shit australia puts refugees processed path pr citizenship almost well-off citizens places like germany treat second-class people indefinitely unless get deported want really help people accept refugees refugee camps pretty well make refugee camps better could also push better treatment resettled refugees countries permanent resettlement seen option many countries `` come years go home longer danger '' many countries say better refugees wait war end go home bullshit inhumane many countries take stance fighting australia countries treat resettled refugees like real people fix worlds problems\n",
      "\n",
      "Review # 7\n",
      "i got my 1v1 once as soraka vs xin and owned him afterwards he said u were right\n",
      "know feel bro u get offers u actually take u make silly-sounding offers peoples think win guy clue game flamed like hell told simply doesnt mindset skillset call bad player simply told could crash even play soraka champ wants since pretty sure isnt good enogh know counters stuff agreed soraka picked xin 1v1 smashed face ground end game came said `` okay gg good player bad notice exactly u said earlier '' crying see awesome behaviour even stupid players would rage say luck\n",
      "\n",
      "Review # 8\n",
      "2700 delegates and representatives from all over china elect a central committee ~370 from a pre-chosen party list which in turn elects a politburo 24 members the politburo then elects an exclusive 9-member committee called the standing committee the head of this is the president\n",
      "chinese system exactly transparent several decent attempts seen national people 's congress basically huge gathering important people china leaders generals party chiefs governors mayors managers big state-owned business etc regional officials consider 'grassroots role models range teachers doctors farmers scientists big important people make 70 role models 30 congress happens every five years elects ~370 people become part party 's elite central committee selected pool people bit ~370 see problem elected committee chooses 24 members also kind pre-chosen state party 's leadership anyway 24 members called politburo decide new standing committee new standing committee elite elite revealed first meeting central committee currently 9 members pretty exclusive rumoured go 7 make quick decision making power chinese government even quicker making decisions 'll less discussion wake reforms top elite elite standing comittee chair also president china\n",
      "\n",
      "Review # 9\n",
      "i have seen mary poppins at least 1400 times\n",
      "confident watched mary poppins anyone earth child living semi-developed country inherited busted betamax player father handy sort somehow managed fix wedged inside tape mary poppins one ever likely get hands given little island cut rest world time mother worked small bar beach one places island electricity chance old tv back one day mother working sat office usual assortment books pencils paper started movie background transfixed immediately soon learned rewind tape watched mary poppins loop day day well year later told movies existed moved england would able watch eventually wore tape would watched three five times daily six days week least fifteen months even low-end estimate would mean watched movie 1400 times quickly abandoned discovered movies fact exist would memorised practically every detail every frame film oddly barely remember anything movie today\n",
      "\n",
      "Review # 10\n",
      "covenant were shitty ground troops but space superiority gave them the upper hand\n",
      "would happen covenant smart halo lore reason covies lost idea combat sort close-ranged honor-based system humans massive hammers glowing sword sorta outdated gunpowder become accurate long distances elites brutes saw par-for-the-course tech reflects build tanks short-range slow-moving mortar could tank faster damaging shell want thin enemy right behind wall swordsmen focus infantry front addition covanent saw forerunner tech sacrosanct updating sin thus human tech technically simple could effective employed intellegently problem faced unsc fight space human ships generally frail packed less firepower instance mac guns unsc frigates required minute fully charge needed pointed right direction slower moving ship facing faster-moving ship using mac guns would suicidal without extensive preperation\n",
      "\n",
      "Review # 11\n",
      "i think this whole issue can be solved with some enforced publicly known rules\n",
      "furthermore mumble courtesy said fall rules subreddit server banned subreddit really way complain banned mumble result almost nil still fully capable acting complaining server within servers community according admission exultant members ckc server 's culture mumble furthermore users encouraged use global chat cut user mumble forcibly remove form communication cut section community however think problem rules ever declared mumble put place similar rule sub reddit cant make channels raciest names addition maybe warning could sent owner channel giving warning continue break rules ban could point rules take action community would accepting odj knew consequences actions feel action justified ojd 's case however aware difficult talk exultant understand reaction community rules like perhaps making way us publicly aware order yet scene\n",
      "\n",
      "Review # 12\n",
      "we are all stupid in our own special way do not blame faith when it is just the cover up not the real issue treat everyone better and help them learn rather than belittling them for not knowing but assuming just like you do\n",
      "base decisions faith trust people told world round scientifically prove gone around proving every little piece science blew way problem faith science schools teach political positions problem people decide use faith views ideals tear others take faith never real problem treating people poorly making things us vs. always issue even `` science '' purported certain peoples genetically disposed inferior faith speakers lack personal responsibility accountability consideration others sure better term missing faith though faith often excuse used claim destruction okay want destroy already lack sympathy already faith used cover used op avoid seeing real problem parsing better solution never good belittle think little others stupid special ways better lend friendly hand help educate introduce truth remember op perpetrating issues railing stop war warring stop whore whorring soap box\n",
      "\n",
      "Review # 13\n",
      "stop blaming the religion and get back to bling the people levering it as an excuse to defend their actions or gain power over others\n",
      "whole world teach racism bigotry taught kids years years slowly defeating idea point rebel science learn love second saying faith science faith religion saying faith scientists faith religious leaders track records good bad deeds time bad deeds religious leaders blamed religion bad deeds scientists blamed doers companies supporting science treated religion like science stop thinking saying religion like science know would blame church pastors people involved pope would defend church 's protection child abusers instead allowed religion considered `` special '' tax exempt considered reproach many circles religion science blame religion contradicts often enough show supposed take literally blame selfish people use create abuses hate\n",
      "\n",
      "Review # 14\n",
      "fapping can only end badly in the long run so keep up no fap\n",
      "would defiantly suggest keeping already experience ed issues get worse secondly speaking one problems starting helps lot channel drive something productive go work join club school study harder hell read news educate pick million actives could instead fapping guarantee productive better use time 24 much older short 5 years went fapping daily short period wasting hours hours watching porn slow steady decline end badly lastly speaking one finally gotten past 7 days first time feels really good know\n",
      "\n",
      "Review # 15\n",
      "vehicles used to be crutches for low-skill players the tweaks made force vehicle operators to do so with skill and planning\n",
      "vehicles changed let tell vehicles already higher threshholds experience reach plasma ghost would blow every single time even guy got brand spankin new ghost case anything think damage threshholds might need lowered thought h3 reach 's transition small arms fire meaningfully damage vehicles positive one glad 343 continued trend friends went back played h3 nobody 's surprise played btb valhalla shooting banshee br felt like shooting angry glances instead bullets cunt wound going something like +20 games fun games someone vehicle dominates fun one person person vehicle damage threshholds way forces person operating vehicle skill instead vehicle providing `` insta-skill '' lacking basically still possible scrap together good sprees vehicles 've got go smart way rush mantis take cover let vehicle shields recharge know tank gets destroyed nearly instantaneously fuck 's sake get\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspecting some of the reviews\n",
    "for i in range(15):\n",
    "    print(\"Review #\",i+1)\n",
    "    print(pdf.summary[i])\n",
    "    print(pdf.content[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(strip_accents=ascii)\n",
    "cv.fit_transform(pdf['content'])\n",
    "vocab = cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302392"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
